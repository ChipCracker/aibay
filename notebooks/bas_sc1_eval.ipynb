{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro_cell",
   "metadata": {},
   "source": [
    "# BAS SC1 – ASR-Evaluierung: Whisper Large V3 vs. Parakeet TDT v3\n",
    "\n",
    "Dieses Notebook lädt die aggregierten Ergebnisse aus `bas_sc1.csv` und vergleicht die Performance von zwei State-of-the-Art ASR-Modellen:\n",
    "- **Whisper Large V3** (OpenAI)\n",
    "- **Parakeet TDT v3** (NVIDIA)\n",
    "\n",
    "Das BAS SC1-Korpus ist ein **mehrsprachiger Datensatz** mit Sprecher:innen unterschiedlicher Muttersprachen und Herkunftsländer. \n",
    "Die Word Error Rate (WER) wird in Abhängigkeit von:\n",
    "- **Muttersprache** (`mother_tongue_iso639_3`)\n",
    "- **Herkunftsland** (`country`)\n",
    "- **L1 vs. L2 Deutsch** (Muttersprachler vs. Fremdsprachenlerner)\n",
    "\n",
    "analysiert.\n",
    "\n",
    "## Schritte\n",
    "- Daten und Metadaten aus dem `OUTPUT_PATH` laden\n",
    "- Vergleichende Kennzahlen für beide Modelle berechnen\n",
    "- WER-Verteilungen beider Modelle visualisieren und vergleichen\n",
    "- Muttersprachen gruppieren und analysieren\n",
    "- Durchschnittliche WER je Muttersprache für beide Modelle analysieren\n",
    "- L1 vs. L2 Deutsch-Sprecher:innen vergleichen\n",
    "- Identifizieren, welches Modell für welche Sprachgruppen besser abschneidet"
   ]
  },
  {
   "cell_type": "code",
   "id": "imports_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T08:59:37.026527Z",
     "start_time": "2025-10-11T08:59:36.247848Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import paths\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "load_data_cell",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-11T08:59:37.154748Z",
     "start_time": "2025-10-11T08:59:37.030483Z"
    }
   },
   "source": [
    "output_root = Path(paths.OUTPUT_PATH or \"\").expanduser()\n",
    "if not output_root.is_dir():\n",
    "    raise FileNotFoundError(\"OUTPUT_PATH ist nicht gesetzt oder verweist auf kein existierendes Verzeichnis.\")\n",
    "\n",
    "csv_path = output_root / \"bas_sc1.csv\"\n",
    "if not csv_path.is_file():\n",
    "    raise FileNotFoundError(f\"Erwartete Datei {csv_path} wurde nicht gefunden.\")\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Convert WER columns to numeric for both models\n",
    "df[\"whisper_large_v3_wer\"] = pd.to_numeric(df[\"whisper_large_v3_wer\"], errors=\"coerce\")\n",
    "\n",
    "# Check if Parakeet column exists (for backward compatibility with old CSV files)\n",
    "has_parakeet = \"parakeet_tdt_v3_wer\" in df.columns\n",
    "if has_parakeet:\n",
    "    df[\"parakeet_tdt_v3_wer\"] = pd.to_numeric(df[\"parakeet_tdt_v3_wer\"], errors=\"coerce\")\n",
    "    print(f\"✓ Beide Modelle verfügbar: Whisper Large V3 & Parakeet TDT v3\")\n",
    "else:\n",
    "    print(\"⚠ Nur Whisper Large V3 verfügbar (Parakeet-Spalte fehlt in CSV)\")\n",
    "\n",
    "print(f\"Anzahl Aufnahmen: {len(df):,}\")\n",
    "\n",
    "# Display relevant columns\n",
    "display_cols = [\"speaker_id\", \"mother_tongue_iso639_3\", \"country\", \"whisper_large_v3_wer\"]\n",
    "if has_parakeet:\n",
    "    display_cols.append(\"parakeet_tdt_v3_wer\")\n",
    "df[display_cols].head()"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Erwartete Datei bas_sc1.csv wurde nicht gefunden.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m csv_path \u001B[38;5;241m=\u001B[39m output_root \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbas_sc1.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m csv_path\u001B[38;5;241m.\u001B[39mis_file():\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mErwartete Datei \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcsv_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m wurde nicht gefunden.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(csv_path)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Convert WER columns to numeric for both models\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Erwartete Datei bas_sc1.csv wurde nicht gefunden."
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistics_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleichende Statistiken für beide Modelle\n",
    "if has_parakeet:\n",
    "    comparison_stats = pd.DataFrame({\n",
    "        \"Whisper Large V3\": df[\"whisper_large_v3_wer\"].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9]),\n",
    "        \"Parakeet TDT v3\": df[\"parakeet_tdt_v3_wer\"].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "    })\n",
    "    \n",
    "    # Fehlende Werte\n",
    "    missing_whisper = df[\"whisper_large_v3_wer\"].isna().sum()\n",
    "    missing_parakeet = df[\"parakeet_tdt_v3_wer\"].isna().sum()\n",
    "    print(f\"Fehlende WER-Werte → Whisper: {missing_whisper}, Parakeet: {missing_parakeet}\")\n",
    "    \n",
    "    comparison_stats\n",
    "else:\n",
    "    # Nur Whisper verfügbar\n",
    "    missing = df[\"whisper_large_v3_wer\"].isna().sum()\n",
    "    print(f\"Fehlende WER-Werte: {missing}\")\n",
    "    wer_summary = df[\"whisper_large_v3_wer\"].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "    wer_summary.to_frame(name=\"Whisper Large V3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histogram_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_parakeet:\n",
    "    # Zwei Histogramme nebeneinander für direkten Vergleich\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Whisper Large V3\n",
    "    whisper_wer = df[\"whisper_large_v3_wer\"].dropna()\n",
    "    axes[0].hist(whisper_wer, bins=30, color=\"#3B82F6\", edgecolor=\"white\", alpha=0.8)\n",
    "    whisper_median = whisper_wer.median()\n",
    "    axes[0].axvline(whisper_median, color=\"#EF4444\", linestyle=\"--\", linewidth=2, label=f\"Median = {whisper_median:.3f}\")\n",
    "    axes[0].set_xlabel(\"Word Error Rate (WER)\")\n",
    "    axes[0].set_ylabel(\"Anzahl Aufnahmen\")\n",
    "    axes[0].set_title(\"Whisper Large V3\")\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Parakeet TDT v3\n",
    "    parakeet_wer = df[\"parakeet_tdt_v3_wer\"].dropna()\n",
    "    axes[1].hist(parakeet_wer, bins=30, color=\"#10B981\", edgecolor=\"white\", alpha=0.8)\n",
    "    parakeet_median = parakeet_wer.median()\n",
    "    axes[1].axvline(parakeet_median, color=\"#EF4444\", linestyle=\"--\", linewidth=2, label=f\"Median = {parakeet_median:.3f}\")\n",
    "    axes[1].set_xlabel(\"Word Error Rate (WER)\")\n",
    "    axes[1].set_ylabel(\"Anzahl Aufnahmen\")\n",
    "    axes[1].set_title(\"Parakeet TDT v3\")\n",
    "    axes[1].legend()\n",
    "    \n",
    "    fig.suptitle(\"WER-Verteilung im BAS-SC1 Korpus: Whisper vs. Parakeet\", fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    # Nur Whisper verfügbar (Fallback)\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    wer_values = df[\"whisper_large_v3_wer\"].dropna()\n",
    "    ax.hist(wer_values, bins=30, color=\"#3B82F6\", edgecolor=\"white\")\n",
    "    median_wer = wer_values.median()\n",
    "    ax.axvline(median_wer, color=\"#EF4444\", linestyle=\"--\", label=f\"Median = {median_wer:.3f}\")\n",
    "    ax.set_xlabel(\"Word Error Rate (WER)\")\n",
    "    ax.set_ylabel(\"Anzahl Aufnahmen\")\n",
    "    ax.set_title(\"Verteilung der Whisper-Large-V3 WER im BAS-SC1 Korpus\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scatter_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_parakeet:\n",
    "    # Direkter Vergleich: Scatter-Plot Whisper vs. Parakeet\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    # Nur gültige Paare (beide Werte vorhanden)\n",
    "    comparison_df = df[[\"whisper_large_v3_wer\", \"parakeet_tdt_v3_wer\"]].dropna()\n",
    "    \n",
    "    ax.scatter(comparison_df[\"whisper_large_v3_wer\"], \n",
    "               comparison_df[\"parakeet_tdt_v3_wer\"], \n",
    "               alpha=0.5, s=40, color=\"#8B5CF6\", edgecolors=\"white\", linewidth=0.5)\n",
    "    \n",
    "    # Diagonale: Perfekte Übereinstimmung\n",
    "    max_val = max(comparison_df[\"whisper_large_v3_wer\"].max(), comparison_df[\"parakeet_tdt_v3_wer\"].max())\n",
    "    ax.plot([0, max_val], [0, max_val], 'r--', linewidth=2, alpha=0.7, label=\"Perfekte Übereinstimmung\")\n",
    "    \n",
    "    # Bereiche markieren\n",
    "    ax.fill_between([0, max_val], [0, max_val], max_val, alpha=0.1, color=\"green\", label=\"Parakeet besser\")\n",
    "    ax.fill_between([0, max_val], 0, [0, max_val], alpha=0.1, color=\"blue\", label=\"Whisper besser\")\n",
    "    \n",
    "    ax.set_xlabel(\"Whisper Large V3 WER\", fontsize=12)\n",
    "    ax.set_ylabel(\"Parakeet TDT v3 WER\", fontsize=12)\n",
    "    ax.set_title(\"Direkter Vergleich: Whisper vs. Parakeet (pro Aufnahme)\", fontsize=14)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # Statistik anzeigen\n",
    "    whisper_better = (comparison_df[\"whisper_large_v3_wer\"] < comparison_df[\"parakeet_tdt_v3_wer\"]).sum()\n",
    "    parakeet_better = (comparison_df[\"parakeet_tdt_v3_wer\"] < comparison_df[\"whisper_large_v3_wer\"]).sum()\n",
    "    tied = (comparison_df[\"whisper_large_v3_wer\"] == comparison_df[\"parakeet_tdt_v3_wer\"]).sum()\n",
    "    \n",
    "    stats_text = f\"Whisper besser: {whisper_better} ({whisper_better/len(comparison_df)*100:.1f}%)\\n\"\n",
    "    stats_text += f\"Parakeet besser: {parakeet_better} ({parakeet_better/len(comparison_df)*100:.1f}%)\\n\"\n",
    "    stats_text += f\"Gleich: {tied}\"\n",
    "    \n",
    "    ax.text(0.98, 0.02, stats_text, transform=ax.transAxes, \n",
    "            fontsize=10, verticalalignment='bottom', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    print(f\"Verglichene Aufnahmen: {len(comparison_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grouping_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muttersprachen-Gruppierung\n",
    "def normalize_language(iso_code: str, country: str) -> str:\n",
    "    \"\"\"Normalisiert Muttersprache für Gruppierung.\"\"\"\n",
    "    if pd.isna(iso_code) or not iso_code or iso_code == \"-\":\n",
    "        # Fallback auf Land\n",
    "        if pd.isna(country) or not country or country == \"-\":\n",
    "            return \"Unbekannt\"\n",
    "        return f\"{country} (Land)\"\n",
    "    return iso_code.upper().strip()\n",
    "\n",
    "df[\"language_group\"] = df.apply(\n",
    "    lambda row: normalize_language(row[\"mother_tongue_iso639_3\"], row[\"country\"]), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Deutsch-Muttersprachler identifizieren (für L1 vs. L2 Analyse)\n",
    "GERMAN_CODES = {\"DEU\", \"GER\", \"GRM\"}  # ISO 639-3 Varianten\n",
    "df[\"is_german_l1\"] = df[\"language_group\"].apply(lambda x: x in GERMAN_CODES)\n",
    "\n",
    "print(f\"Anzahl Sprachgruppen: {df['language_group'].nunique()}\")\n",
    "print(f\"\\nVerteilung der Top 10 Muttersprachen:\")\n",
    "print(df[\"language_group\"].value_counts().head(10))\n",
    "print(f\"\\nDeutsch L1: {df['is_german_l1'].sum()}, Andere: {(~df['is_german_l1']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metrics_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 3\n",
    "\n",
    "if has_parakeet:\n",
    "    # Metriken für beide Modelle aggregieren\n",
    "    metrics = (\n",
    "        df.dropna(subset=[\"whisper_large_v3_wer\", \"parakeet_tdt_v3_wer\"])\n",
    "          .groupby(\"language_group\")\n",
    "          .agg(\n",
    "              samples=(\"whisper_large_v3_wer\", \"count\"),\n",
    "              whisper_mean=(\"whisper_large_v3_wer\", \"mean\"),\n",
    "              whisper_median=(\"whisper_large_v3_wer\", \"median\"),\n",
    "              whisper_std=(\"whisper_large_v3_wer\", \"std\"),\n",
    "              parakeet_mean=(\"parakeet_tdt_v3_wer\", \"mean\"),\n",
    "              parakeet_median=(\"parakeet_tdt_v3_wer\", \"median\"),\n",
    "              parakeet_std=(\"parakeet_tdt_v3_wer\", \"std\"),\n",
    "          )\n",
    "    )\n",
    "    \n",
    "    # Differenz berechnen (positiv = Parakeet schlechter, negativ = Parakeet besser)\n",
    "    metrics[\"wer_diff\"] = metrics[\"parakeet_mean\"] - metrics[\"whisper_mean\"]\n",
    "    metrics[\"avg_wer\"] = (metrics[\"whisper_mean\"] + metrics[\"parakeet_mean\"]) / 2\n",
    "    \n",
    "    language_overview = (\n",
    "        metrics.loc[metrics[\"samples\"] >= min_samples]\n",
    "        .sort_values(\"avg_wer\")\n",
    "        .round({\"whisper_mean\": 3, \"whisper_median\": 3, \"whisper_std\": 3,\n",
    "                \"parakeet_mean\": 3, \"parakeet_median\": 3, \"parakeet_std\": 3,\n",
    "                \"wer_diff\": 3, \"avg_wer\": 3})\n",
    "    )\n",
    "    \n",
    "    print(f\"Sprachgruppen mit mindestens {min_samples} Aufnahmen: {len(language_overview)}\")\n",
    "    print(f\"Durchschnittliche WER-Differenz (Parakeet - Whisper): {metrics['wer_diff'].mean():.3f}\")\n",
    "    language_overview\n",
    "else:\n",
    "    # Nur Whisper (Fallback)\n",
    "    metrics = (\n",
    "        df.dropna(subset=[\"whisper_large_v3_wer\"])\n",
    "          .groupby(\"language_group\")\n",
    "          .agg(\n",
    "              samples=(\"whisper_large_v3_wer\", \"count\"),\n",
    "              mean_wer=(\"whisper_large_v3_wer\", \"mean\"),\n",
    "              median_wer=(\"whisper_large_v3_wer\", \"median\"),\n",
    "              std_wer=(\"whisper_large_v3_wer\", \"std\"),\n",
    "              wer_p25=(\"whisper_large_v3_wer\", lambda s: s.quantile(0.25)),\n",
    "              wer_p75=(\"whisper_large_v3_wer\", lambda s: s.quantile(0.75)),\n",
    "          )\n",
    "    )\n",
    "    \n",
    "    language_overview = (\n",
    "        metrics.loc[metrics[\"samples\"] >= min_samples]\n",
    "        .sort_values(\"mean_wer\")\n",
    "        .round({\"mean_wer\": 3, \"median_wer\": 3, \"std_wer\": 3, \"wer_p25\": 3, \"wer_p75\": 3})\n",
    "    )\n",
    "    \n",
    "    print(f\"Sprachgruppen mit mindestens {min_samples} Aufnahmen: {len(language_overview)}\")\n",
    "    language_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "barchart_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = language_overview\n",
    "if plot_df.empty:\n",
    "    print(\"Keine Sprachgruppen erfüllen die Mindestanzahl für die Visualisierung.\")\n",
    "elif has_parakeet:\n",
    "    # Grouped Bar Chart für beide Modelle\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    languages = plot_df.index\n",
    "    x = list(range(len(languages)))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Balken für beide Modelle\n",
    "    whisper_bars = ax.barh([i - width/2 for i in x], plot_df[\"whisper_mean\"], \n",
    "                            height=width, color=\"#3B82F6\", alpha=0.8, label=\"Whisper Large V3\")\n",
    "    parakeet_bars = ax.barh([i + width/2 for i in x], plot_df[\"parakeet_mean\"], \n",
    "                             height=width, color=\"#10B981\", alpha=0.8, label=\"Parakeet TDT v3\")\n",
    "    \n",
    "    # Sample-Zahlen anzeigen\n",
    "    for i, (w_mean, p_mean, samples) in enumerate(zip(plot_df[\"whisper_mean\"], \n",
    "                                                        plot_df[\"parakeet_mean\"], \n",
    "                                                        plot_df[\"samples\"])):\n",
    "        max_val = max(w_mean, p_mean)\n",
    "        ax.text(max_val + 0.01, i, f\"n={samples}\", va=\"center\", fontsize=9)\n",
    "    \n",
    "    ax.set_yticks(x)\n",
    "    ax.set_yticklabels(languages)\n",
    "    ax.set_xlabel(\"Word Error Rate (Mittelwert)\", fontsize=11)\n",
    "    ax.set_title(\"Durchschnittliche WER je Muttersprache: Whisper vs. Parakeet\", fontsize=13)\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    # Nur Whisper (Fallback)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    y_positions = list(range(len(plot_df)))\n",
    "    ax.barh(y_positions, plot_df[\"mean_wer\"], color=\"#2563EB\", alpha=0.8, label=\"Mittelwert\")\n",
    "    for idx, (lower, upper) in enumerate(zip(plot_df[\"wer_p25\"], plot_df[\"wer_p75\"])):\n",
    "        ax.hlines(idx, lower, upper, color=\"#F97316\", linewidth=4, label=\"IQR\" if idx == 0 else \"\")\n",
    "    for idx, (mean, samples) in enumerate(zip(plot_df[\"mean_wer\"], plot_df[\"samples\"])):\n",
    "        ax.text(mean + 0.005, idx, f\"n={samples}\", va=\"center\", fontsize=9)\n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels(plot_df.index)\n",
    "    ax.set_xlabel(\"Word Error Rate\")\n",
    "    ax.set_title(\"Durchschnittliche WER je Muttersprache (IQR als Linie)\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxplot_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_groups = metrics.sort_values(\"samples\", ascending=False).head(8).index\n",
    "subset = df[df[\"language_group\"].isin(top_groups)].copy()\n",
    "\n",
    "if subset.empty:\n",
    "    print(\"Keine ausreichenden Daten für die Boxplot-Visualisierung.\")\n",
    "elif has_parakeet:\n",
    "    # Boxplots für beide Modelle nebeneinander\n",
    "    subset[\"language_group\"] = pd.Categorical(subset[\"language_group\"], categories=top_groups, ordered=True)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    # Manueller grouped boxplot\n",
    "    whisper_positions = []\n",
    "    parakeet_positions = []\n",
    "    box_width = 0.35\n",
    "    \n",
    "    for i in range(len(top_groups)):\n",
    "        whisper_positions.append(i * 2 - box_width/2)\n",
    "        parakeet_positions.append(i * 2 + box_width/2)\n",
    "    \n",
    "    # Whisper Boxplots\n",
    "    whisper_boxdata = [subset[subset[\"language_group\"] == g][\"whisper_large_v3_wer\"].dropna().values \n",
    "                       for g in top_groups]\n",
    "    bp1 = ax.boxplot(whisper_boxdata, positions=whisper_positions, widths=box_width,\n",
    "                     patch_artist=True, boxprops=dict(facecolor=\"#3B82F6\", alpha=0.7),\n",
    "                     medianprops=dict(color=\"red\", linewidth=2))\n",
    "    \n",
    "    # Parakeet Boxplots\n",
    "    parakeet_boxdata = [subset[subset[\"language_group\"] == g][\"parakeet_tdt_v3_wer\"].dropna().values \n",
    "                        for g in top_groups]\n",
    "    bp2 = ax.boxplot(parakeet_boxdata, positions=parakeet_positions, widths=box_width,\n",
    "                     patch_artist=True, boxprops=dict(facecolor=\"#10B981\", alpha=0.7),\n",
    "                     medianprops=dict(color=\"red\", linewidth=2))\n",
    "    \n",
    "    # X-Achse konfigurieren\n",
    "    ax.set_xticks([i * 2 for i in range(len(top_groups))])\n",
    "    ax.set_xticklabels(top_groups, rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Word Error Rate\")\n",
    "    ax.set_title(\"WER-Verteilung der meist vertretenen Sprachgruppen: Whisper vs. Parakeet\", fontsize=13)\n",
    "    \n",
    "    # Legende\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor='#3B82F6', alpha=0.7, label='Whisper Large V3'),\n",
    "                      Patch(facecolor='#10B981', alpha=0.7, label='Parakeet TDT v3')]\n",
    "    ax.legend(handles=legend_elements, loc='upper left')\n",
    "    \n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    # Nur Whisper (Fallback)\n",
    "    subset[\"language_group\"] = pd.Categorical(subset[\"language_group\"], categories=top_groups, ordered=True)\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    subset.boxplot(column=\"whisper_large_v3_wer\", by=\"language_group\", ax=ax, grid=False)\n",
    "    ax.set_ylabel(\"Word Error Rate\")\n",
    "    ax.set_xlabel(\"Muttersprache\")\n",
    "    ax.set_title(\"WER-Verteilung der meist vertretenen Sprachgruppen\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "winner_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_parakeet:\n",
    "    # Performance-Gewinner-Analyse: Welches Modell ist bei welcher Sprache besser?\n",
    "    winner_df = language_overview[[\"samples\", \"whisper_mean\", \"parakeet_mean\", \"wer_diff\"]].copy()\n",
    "    winner_df[\"winner\"] = winner_df[\"wer_diff\"].apply(\n",
    "        lambda x: \"Whisper\" if x > 0 else (\"Parakeet\" if x < 0 else \"Gleich\")\n",
    "    )\n",
    "    winner_df[\"abs_diff\"] = winner_df[\"wer_diff\"].abs()\n",
    "    \n",
    "    # Nach größter absoluter Differenz sortieren\n",
    "    winner_df_sorted = winner_df.sort_values(\"abs_diff\", ascending=False)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MODELL-PERFORMANCE PRO SPRACHGRUPPE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nWhisper gewinnt bei: {(winner_df['winner'] == 'Whisper').sum()} Sprachen\")\n",
    "    print(f\"Parakeet gewinnt bei: {(winner_df['winner'] == 'Parakeet').sum()} Sprachen\")\n",
    "    print(f\"Unentschieden: {(winner_df['winner'] == 'Gleich').sum()} Sprachen\")\n",
    "    print(f\"\\nDurchschnittliche absolute Differenz: {winner_df['abs_diff'].mean():.3f}\")\n",
    "    print(\"\\nTop 10 größte Unterschiede:\")\n",
    "    print(winner_df_sorted[[\"whisper_mean\", \"parakeet_mean\", \"wer_diff\", \"winner\"]].head(10))\n",
    "    \n",
    "    # Visualisierung: WER-Differenz pro Sprache\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    languages = winner_df_sorted.index\n",
    "    diffs = winner_df_sorted[\"wer_diff\"]\n",
    "    colors = [\"#3B82F6\" if d > 0 else \"#10B981\" for d in diffs]\n",
    "    \n",
    "    y_pos = list(range(len(languages)))\n",
    "    ax.barh(y_pos, diffs, color=colors, alpha=0.8)\n",
    "    \n",
    "    # Null-Linie\n",
    "    ax.axvline(0, color='black', linewidth=1, linestyle='-', alpha=0.5)\n",
    "    \n",
    "    # Beschriftungen\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(languages)\n",
    "    ax.set_xlabel(\"WER-Differenz (Parakeet - Whisper)\\n← Whisper besser | Parakeet besser →\", fontsize=11)\n",
    "    ax.set_title(\"Modell-Performance-Vergleich pro Sprachgruppe\", fontsize=14)\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Legende\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#3B82F6', alpha=0.8, label='Whisper besser'),\n",
    "        Patch(facecolor='#10B981', alpha=0.8, label='Parakeet besser')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    winner_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l1_vs_l2_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1 vs. L2 Deutsch-Analyse\n",
    "if has_parakeet:\n",
    "    l1_l2_metrics = (\n",
    "        df.dropna(subset=[\"whisper_large_v3_wer\", \"parakeet_tdt_v3_wer\"])\n",
    "          .groupby(\"is_german_l1\")\n",
    "          .agg(\n",
    "              samples=(\"whisper_large_v3_wer\", \"count\"),\n",
    "              whisper_mean=(\"whisper_large_v3_wer\", \"mean\"),\n",
    "              whisper_std=(\"whisper_large_v3_wer\", \"std\"),\n",
    "              parakeet_mean=(\"parakeet_tdt_v3_wer\", \"mean\"),\n",
    "              parakeet_std=(\"parakeet_tdt_v3_wer\", \"std\"),\n",
    "          )\n",
    "    )\n",
    "    \n",
    "    l1_l2_metrics.index = l1_l2_metrics.index.map({True: \"Deutsch L1\", False: \"Deutsch L2\"})\n",
    "    l1_l2_metrics[\"wer_diff\"] = l1_l2_metrics[\"parakeet_mean\"] - l1_l2_metrics[\"whisper_mean\"]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"L1 vs. L2 DEUTSCH: MODELLVERGLEICH\")\n",
    "    print(\"=\" * 80)\n",
    "    print(l1_l2_metrics.round(3))\n",
    "    \n",
    "    # Visualisierung\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    x_pos = [0, 1]\n",
    "    width = 0.35\n",
    "    \n",
    "    whisper_means = l1_l2_metrics[\"whisper_mean\"].values\n",
    "    parakeet_means = l1_l2_metrics[\"parakeet_mean\"].values\n",
    "    labels = l1_l2_metrics.index.tolist()\n",
    "    \n",
    "    ax.bar([x - width/2 for x in x_pos], whisper_means, width, \n",
    "           label='Whisper Large V3', color='#3B82F6', alpha=0.8)\n",
    "    ax.bar([x + width/2 for x in x_pos], parakeet_means, width,\n",
    "           label='Parakeet TDT v3', color='#10B981', alpha=0.8)\n",
    "    \n",
    "    ax.set_ylabel('Word Error Rate (Mittelwert)', fontsize=11)\n",
    "    ax.set_title('L1 vs. L2 Deutsch: Modellvergleich', fontsize=13)\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Sample-Zahlen als Text\n",
    "    for i, (w, p, n) in enumerate(zip(whisper_means, parakeet_means, l1_l2_metrics[\"samples\"])):\n",
    "        max_val = max(w, p)\n",
    "        ax.text(i, max_val + 0.01, f\"n={n}\", ha='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    l1_l2_metrics = (\n",
    "        df.dropna(subset=[\"whisper_large_v3_wer\"])\n",
    "          .groupby(\"is_german_l1\")\n",
    "          .agg(\n",
    "              samples=(\"whisper_large_v3_wer\", \"count\"),\n",
    "              mean_wer=(\"whisper_large_v3_wer\", \"mean\"),\n",
    "              std_wer=(\"whisper_large_v3_wer\", \"std\"),\n",
    "          )\n",
    "    )\n",
    "    \n",
    "    l1_l2_metrics.index = l1_l2_metrics.index.map({True: \"Deutsch L1\", False: \"Deutsch L2\"})\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"L1 vs. L2 DEUTSCH\")\n",
    "    print(\"=\" * 80)\n",
    "    print(l1_l2_metrics.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_cell",
   "metadata": {},
   "source": [
    "## Zusammenfassung & Hinweise\n",
    "\n",
    "**Methodik**\n",
    "- Beide Modelle (Whisper Large V3 und Parakeet TDT v3) werden mit identischen Ground-Truth-Transkriptionen evaluiert.\n",
    "- WER-Berechnung erfolgt mit denselben Normalisierungsregeln für faire Vergleichbarkeit.\n",
    "- Sprachgruppen basieren auf `mother_tongue_iso639_3` (ISO 639-3 Sprachcodes).\n",
    "\n",
    "**BAS SC1 Besonderheiten**\n",
    "- Mehrsprachiger Korpus mit Sprecher:innen unterschiedlicher Herkunft und Muttersprachen.\n",
    "- Besonders interessant: Vergleich zwischen Deutsch-Muttersprachler:innen (L1) und Deutsch als Fremdsprache (L2).\n",
    "- Keine Dialektinformationen wie bei RVG1, stattdessen sprachliche und geografische Diversität.\n",
    "\n",
    "**Interpretationshinweise**\n",
    "- Performance-Unterschiede zwischen L1 und L2 können auf Akzent, Prosodie oder phonetische Abweichungen zurückzuführen sein.\n",
    "- Die Performance-Unterschiede zwischen den Modellen können sprachspezifisch sein und auf unterschiedliche Trainingsdaten hindeuten.\n",
    "- Für feinere Analysen lassen sich die Filterparameter (`min_samples`, `top_groups`) im Notebook anpassen.\n",
    "\n",
    "**Modellvergleich**\n",
    "- Die Scatter-Plot-Analyse zeigt aufnahme-spezifische Performance-Unterschiede zwischen Whisper und Parakeet.\n",
    "- Die WER-Differenz-Visualisierung identifiziert Sprachgruppen, bei denen ein Modell besonders stark oder schwach abschneidet.\n",
    "- L1 vs. L2 Analyse zeigt, ob Modelle bei Muttersprachler:innen oder Fremdsprachenlerner:innen besser funktionieren."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
