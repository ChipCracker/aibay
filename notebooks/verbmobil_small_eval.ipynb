{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "804c5654",
   "metadata": {},
   "source": [
    "\n",
    "# Verbmobil Small – ASR Evaluation\n",
    "\n",
    "Dieses Notebook fasst die Erkennungsleistung der beiden aktuell angebundenen ASR-Pipelines über das `verbmobil_small`-Korpus zusammen. Es setzt voraus, dass du zuvor die Inferenz via\n",
    "\n",
    "```bash\n",
    "python main.py verbmobil_small --model both\n",
    "```\n",
    "\n",
    "ausgeführt hast (ggf. mit angepassten Batch-Größen), sodass die Resultate als CSV im konfigurierten `OUTPUT_PATH` vorliegen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da2c110",
   "metadata": {},
   "source": [
    "\n",
    "## Setup & Daten laden\n",
    "\n",
    "Wir lesen die Ergebnisse aus dem `OUTPUT_PATH` (oder dem Standardordner `outputs/`), prüfen die wichtigsten Spalten und verschaffen uns einen ersten Überblick über die Datenmenge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Final\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "OUTPUT_PATH = os.getenv(\"OUTPUT_PATH\")\n",
    "OUTPUT_DIR: Final[Path] = Path(OUTPUT_PATH) if OUTPUT_PATH else Path(\"outputs\")\n",
    "DATASET_CSV: Final[Path] = OUTPUT_DIR / \"verbmobil_small.csv\"\n",
    "\n",
    "print(f\"OUTPUT_DIR: {OUTPUT_DIR}\")\n",
    "print(f\"CSV-Datei: {DATASET_CSV}\")\n",
    "\n",
    "if not DATASET_CSV.is_file():\n",
    "    raise FileNotFoundError(\n",
    "        \"Keine Verbmobil-Ergebnisse gefunden. Führe zuerst `python main.py verbmobil_small --model both` aus \"\n",
    "        \"oder passe den Pfad an.\"\n",
    "    )\n",
    "\n",
    "raw_df = pd.read_csv(DATASET_CSV)\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row_count = len(raw_df)\n",
    "present_columns = sorted(raw_df.columns)\n",
    "\n",
    "print(f\"Zeilen (Segments): {row_count:,}\")\n",
    "print(\"Verfügbare Spalten:\")\n",
    "for col in present_columns:\n",
    "    print(f\"  - {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e142893",
   "metadata": {},
   "source": [
    "\n",
    "## WER-Überblick\n",
    "\n",
    "Wir fokussieren uns auf die Word Error Rate (WER) der Whisper- und Parakeet-Ausgaben. Zusätzlich wird – sofern beide Modelle vorhanden sind – die Differenz betrachtet, um Stärken/Schwächen pro Segment zu identifizieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WER_COLUMNS = [\n",
    "    \"whisper_large_v3_wer\",\n",
    "    \"parakeet_tdt_v3_wer\",\n",
    "]\n",
    "\n",
    "available_wer = [col for col in WER_COLUMNS if col in raw_df.columns]\n",
    "if not available_wer:\n",
    "    raise ValueError(\"Keine WER-Spalten gefunden. Stelle sicher, dass die Inferenz erfolgreich durchlief.\")\n",
    "\n",
    "summary_rows: list[dict[str, float]] = []\n",
    "for col in available_wer:\n",
    "    series = raw_df[col].dropna()\n",
    "    if series.empty:\n",
    "        continue\n",
    "    summary_rows.append(\n",
    "        {\n",
    "            \"metric\": col,\n",
    "            \"count\": int(series.count()),\n",
    "            \"mean\": float(series.mean()),\n",
    "            \"median\": float(series.median()),\n",
    "            \"std\": float(series.std()),\n",
    "            \"p10\": float(series.quantile(0.10)),\n",
    "            \"p90\": float(series.quantile(0.90)),\n",
    "            \"min\": float(series.min()),\n",
    "            \"max\": float(series.max()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "wer_summary = pd.DataFrame(summary_rows)\n",
    "wer_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117fa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_df = raw_df.copy()\n",
    "plot_df = plot_df.melt(\n",
    "    value_vars=[col for col in WER_COLUMNS if col in plot_df.columns],\n",
    "    var_name=\"modell\",\n",
    "    value_name=\"wer\",\n",
    ")\n",
    "plot_df = plot_df.dropna(subset=[\"wer\"])\n",
    "\n",
    "if plot_df.empty:\n",
    "    raise ValueError(\"Keine gültigen WER-Werte zum Plotten verfügbar.\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(data=plot_df, x=\"modell\", y=\"wer\", palette=\"muted\")\n",
    "plt.title(\"Verteilung der WER pro Modell\")\n",
    "plt.ylim(0, min(1.0, plot_df[\"wer\"].max() * 1.05))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.histplot(data=plot_df, x=\"wer\", hue=\"modell\", element=\"step\", stat=\"density\", common_norm=False)\n",
    "plt.title(\"WER-Dichtevergleich\")\n",
    "plt.xlim(0, min(1.0, plot_df[\"wer\"].max() * 1.05))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a45c9d",
   "metadata": {},
   "source": [
    "\n",
    "## Segment-Highlights\n",
    "\n",
    "Zur Einordnung, welche Sequenzen besonders herausfordernd sind, listen wir die zehn höchsten WER-Differenzen auf. Positive Werte bedeuten, dass Parakeet schlechter als Whisper abschneidet, negative Werte deuten auf einen Vorteil für Parakeet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74db676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"whisper_large_v3_wer\" in raw_df.columns and \"parakeet_tdt_v3_wer\" in raw_df.columns:\n",
    "    diff_df = raw_df.dropna(subset=[\"whisper_large_v3_wer\", \"parakeet_tdt_v3_wer\"]).copy()\n",
    "    diff_df[\"wer_diff_parakeet_minus_whisper\"] = diff_df[\"parakeet_tdt_v3_wer\"] - diff_df[\"whisper_large_v3_wer\"]\n",
    "\n",
    "    highlight_columns = []\n",
    "    for candidate in (\"utterance_id\", \"conversation_id\", \"speaker_code\", \"channel\"):\n",
    "        if candidate in diff_df.columns:\n",
    "            highlight_columns.append(candidate)\n",
    "    highlight_columns.extend([\n",
    "        \"wer_diff_parakeet_minus_whisper\",\n",
    "        \"whisper_large_v3_wer\",\n",
    "        \"parakeet_tdt_v3_wer\",\n",
    "    ])\n",
    "\n",
    "    worst_segments = diff_df.nlargest(10, \"wer_diff_parakeet_minus_whisper\")[highlight_columns]\n",
    "    best_segments = diff_df.nsmallest(10, \"wer_diff_parakeet_minus_whisper\")[highlight_columns]\n",
    "\n",
    "    display(worst_segments)\n",
    "    display(best_segments)\n",
    "else:\n",
    "    print(\"Für Segmentvergleiche werden beide WER-Spalten benötigt.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646300bd",
   "metadata": {},
   "source": [
    "\n",
    "## Weiterführende Schritte\n",
    "\n",
    "- Ergänze bei Bedarf eigene Filter (z. B. nach Sprecher*in oder Kanal) und exportiere Teilmengen zur manuellen Qualitätsprüfung.\n",
    "- Nutze `python recompute_wer.py <csv>` für aktualisierte WERs nach manuellen Transkriptanpassungen.\n",
    "- Die Batch-Parameter `--whisper-batch-size` und `--parakeet-batch-size` steuern die Geschwindigkeit der Inferenz.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
